
\chapter{Research Background and the Hypothesis}
\label{chap:kapitel2}

	The research background for this work is enormous through the many aspects of this study. Shape-texture bias, generalization, and sim-to-real are among the major fields for instance-segmentation. 

	\section{State of the Art}
	\label{sec:state-of-the-art}
	
		\paragraph{Methods:} Instance segmentation has become an essential field in computer vision, and much research has been done on different approaches to achieving mask-generation for foreground objects. Still, there are a lot of open questions and investigations \cite{Sharma2022}. There are four big types of state-of-the-art methods: Transformers, reinforcement learning, proposal based (\ac{dnn}) and proposal free (\ac{dnn}) methods \cite{Sharma2022}.\\
		Reinforcement Learning is tricky to use for instance segmentation, and transformers are too inefficient for this complex task, but achieve part-wise high accuracy \cite{Sharma2022}.\\
		This work will not go further into the topic of \ac{dnn} architecture; it is an important field with many open questions.
		\paragraph{Shape Texture Bias:} Most instance segmentation methods tend to have a strong bias towards texture bias \cite{Theodoridis2022}, which is a common problem of \ac{cnn}-based approaches \cite{Geirhos2022}\cite{Baker2018}\cite{Tabak2023}.\\
		Some research tries to apply shape bias to \ac{cnn}-based approaches in similar tasks and show improved accuracy of the used \ac{dnn}s \cite{Geirhos2022}\cite{Hermann2020}; Thus, it comes closer to the human vision \cite{Geirhos2020}\cite{Mohla2022}\cite{Baker2020}.\\
		Recent research claims that shape bias leads not in every case to improved accuracy and generalization, and that a \ac{dnn} with texture bias can achieve state-of-the-art \ac{ood} accuracy in many different scenarios \cite{Qiu2024}. Past research found similar results \cite{Brochu2019}.\\
		Another approach is to de-bias the \ac{dnn}. So it include shape and texture equally in its decision-making process \cite{Li2021}\cite{Co2021}\cite{Chung2023}. Which claims to achieve substantial improvements on ImageNet. \\
		The reason for the existing of texture bias is the shortcut learning from \ac{cnn}s \cite{Geirhos2020}, probably also influence by unnatural data augmentation techniques \cite{Hermann2020}. The segmentation task seems to be easy solvable with texture information in most cases. Shape information still plays a essential rule in decision making \cite{Tabak2023}. More complex decision rules for more complex tasks.\\
		In contrast to past research, recent research states that a bias towards texture or shape can not explain the ability to generalize \cite{Gavrikov2024}. The relevance of bias seems to be in question and is probably not as important as thought.%; otherwise, there would not be so much research on shape texture bias.
		%\paragraph{Generalization:} ...
		\paragraph{Sim-to-real:} Using a synthetic dataset from a virtual environment became the standard procedure to generate a massive amount of labeled data quickly for instance segmentation \cite{Danielczuk2019}\cite{Xie2020}\cite{Xie2021}\cite{Shao2018}\cite{Toda2019}. To overcome the sim-to-real gap, the quality of texture plays a crucial role \cite{Tabak2023}\cite{Martinez2019}; That makes it suitable to use a simulation software with a powerful and realistic-looking renderer for data generation, such as Unreal Engine 5 \cite{Romero2022}.\\
		Another successful technique to transfer well from sim to real is domain randomization \cite{Raj2023}. A variation to the synthetic data is applied to randomly modify shape, texture, colors, lightning (exposure), camera angles and cropping, blur, and noise. These random modifications brings the data closer to reality, where such modification also happens. Thus the improvement is explainable. This variation can also be applied in a data-augmentation step after data generation \cite{Kar2022}.\\
		There are still many open questions to the sim-to-real transfer and a lack of generalization when \ac{dnn}s are only trained on synthetic data \cite{Doersch2019}. Modern and future render technology and highly realistic simulation software could lead to a reduction of this lack.
		\paragraph{Input Type:} Since the beginning of instance segmentation, depth data has played a vital role \cite{Silbermann2012}. It comes from the fact that this is a task based heavily on 3D information. Objects can be stacked on each other, and there may be only a small piece of an object to see. Eventually, the model never saw such an object because this was only part of the object. An understanding of 3D is needed to understand that. To assist an instance segmentation \ac{dnn}, providing information about the depth is an obvious and understandable approach.\\
		How important the depth information really is and if RGB-only images do provide not enough 3D information by themselves is an open question; some recent researches show a trend to RGB-only approaches \cite{Raj2023}\cite{Zakeri2024}.\\
		There is also a depth-information-only approach due to the better sim-to-real ability of depth data, which could caused by the simpler nature of this data type \cite{Danielczuk2019}.\\
		Widespread is the use of depth as the 4th channel (RGB-D), yet the results are disagreed \cite{Lüling2021}\cite{Zakeri2024}.
		But the research gets even further to the question of the best way to implement depth information in \ac{dnn} \cite{Xiang2021}\cite{Xie2020}\cite{Pei2024}\cite{Yasir2022}\cite{Shao2018}\cite{Ye2017}.\\
		Also, the model itself used, for instance segmentation, changes the effectiveness of the used input types \cite{Xiang2021}.\\
		Concluding, it needs to be clarified which input type is preferred. The research found different results. Factors like domain, brightness, \ac{dnn} architecture, and data quality could play a vital role. The success of RGB-only input type in recent research \cite{Raj2023}\cite{Zakeri2024} can maybe be explained by the increased quality of synthetic data but still needs more research to be confirmed.
		\paragraph{Shape Texture Quantity:} Finally, there is no research which investigate in the influence of shape or texture quantity to the the accuracy of instance segmentation. Even if this question seems unimportant at first, a closer look is probably worth it. It appears unambiguous that more shapes and more textures leads to better generalization and accuracy, under the assumption of enough data amount. But the quantity of how much it really improve the accuracy could be very interesting. 



	\section{Related Work}
	\label{sec:related-work}
		Investigating shape texture quantity with depth data towards generalization, bias, and sim-to-real is novel and unique. Therefore, no comparable work is available yet. \\
		\\
		This paper shows, among other things, practical results and shows if research in generalization, bias and sim-to-real is reproducible in this specific practical use-case.\\
		Related work in this context is "Can Biases in ImageNet Models Explain Generalization?" \cite{Gavrikov2024}, "Learning RGB-D Feature Embeddings for Unseen Object Instance Segmentation" \cite{Xiang2021}, "Bin-picking of novel objects through category-agnostic-segmentation: RGB matters" \cite{Raj2023} / "Benchmarking of deep learning algorithms for 3D instance segmentation of confocal image datasets" \cite{Kar2022}, "Towards Synthetic Data: Dealing with the Texture-Bias in Sim2real Learning" \cite{Tabak2023}, "ImageNet-trained CNNs are biased towards texture; increasing shape bias improves accuracy and robustness" \cite{Geirhos2022} and "Shape-biased CNNs are Not Always Superior in Out-of-Distribution Robustness" \cite{Qiu2024}.\\
		These papers a only in a partwise relation to this study and are already discussed in the \ref{sec:state-of-the-art} section.
		For the sim-to-real transfer, a comparison with the "Learning RGB-D Feature Embeddings for Unseen Object Instance Segmentation" \cite{Xiang2021} paper is done, because the work also uses Mask R-CNN \cite{Kaiming2017} and varies with RGB and RGBD as input data. Moreover, it calculates metrics on the OCID dataset \cite{Suchi2019}, an available dataset suitable for bin-picking. The quantity variation is missing.
	
	
	\section{Hypothesis Statement}
	\label{sec:hypothesis-statement}	
		Through 3 experiments, this study will prove or disprove the following three claims. One for the core focus depth, one claim for the core focus quantity, and another for the influence from depth and quantity together: 
		\begin{enumerate}
			\item "Combining RGB and depth data combines texture and shape bias and leads to better generalization and sim-to-real ability." % better instance segmentation results
			\item "More Difference in Shapes leads to a higher Shape-Awareness and achieves better generalization and sim-to-real ability. And more Difference in Texture leads to a higher Texture-Awareness and achieves better generalization and sim-to-real ability."
			\item "When using RGB-D as input, less unique shapes and textures are needed for the same instance segmentation accuracy as using only RGB as Input."
		\end{enumerate}
		The 1. claim was chosen through the findings of a bias towards texture in instance segmentation \cite{Theodoridis2022} and the fact that depth data only contains shape information. In that way, the \ac{dnn} could be encouraged to use shape information more for decision-making. In addition, more balanced decision-making between texture and shape information could lead to better results \cite{Li2021}\cite{Co2021}\cite{Chung2023}.\\
		For the 2. claim, there is no foundation for the claim, apart from the general fact that \ac{dnn}s (and \ac{cnn}s specifically) need a huge amount of data to generalize well. That could mean that more different shapes and textures also increase the ability to generalize, bridge from sim to real, and probably increase the decision-making towards shape/texture.\\
		There is also no foundation for the 3. claim, except due to the additional information about shape and the probably increased shape-awareness, the \ac{dnn} may need fewer different shapes and textures to achieve a similar precision and generalization as the \ac{dnn} trained with only RGB images and more different shapes and textures in the train-data.
	
	



			