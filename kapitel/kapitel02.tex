
\chapter{Research Background and the Hypothesis}
\label{chap:kapitel2}

	The research background for this work is enormous through the many aspects of this study. Shape-texture bias, generalization, and sim-to-real are among the major research fields of instance segmentation. This chapter summarizes research on these topics (see section \ref{sec:state-of-the-art} and \ref{sec:related-work}) and states the hypothesis of this study (see section \ref{sec:hypothesis-statement}).

	\section{State of the Art}
	\label{sec:state-of-the-art}
		\paragraph{Methods:} Instance segmentation has become an essential field in computer vision, and much research has been done on different approaches to achieving precise mask predictions for foreground objects. Still, there are a lot of open questions and investigations \cite{Sharma2022}. The cited paper also states that there are four big types of state-of-the-art machine-learning methods for instance segmentation: Transformers, reinforcement learning, proposal-based (\ac{dnn}), and proposal-free (\ac{dnn}) methods.\\
		Reinforcement Learning is tricky to use for instance segmentation, and transformers are too inefficient for this complex task, but achieve part-wise high accuracy evidenced by the just mentioned paper.\\
		The paper from \citeauthor{Sharma2022} also confirms that proposal-free and proposal-based (\ac{dnn}), like the here used Mask R-CNN \cite{Kaiming2017}, are the most common used and practical useful approaches. With Proposal-based approaches as the baseline for instance segmentation.\\
		This work will not go further into the topic of \ac{dnn} architecture, but it is a necessary field with many open questions.
		\clearpage
		\paragraph{Shape Texture Bias:} Most instance segmentation methods tend to have a strong bias towards texture \cite{Theodoridis2022}, which is a common problem of \ac{cnn}-based approaches \cite{Geirhos2022}\cite{Baker2018}\cite{Tabak2023}.\\
		Some research tries to apply shape bias to \ac{cnn}-based approaches in similar tasks and show improved accuracy of the used \ac{dnn}s \cite{Geirhos2022}\cite{Hermann2020}; because, it comes closer to the human vision \cite{Geirhos2020}\cite{Mohla2022}\cite{Baker2020}.\\
		Recent research claims that shape bias leads not in every case to improved accuracy and generalization and that a \ac{dnn} with texture bias can achieve state-of-the-art \ac{ood} accuracy in many different scenarios \cite{Qiu2024}. Previous studies have reported similar findings \cite{Brochu2019}.\\
		Another approach is to de-bias the \ac{dnn}. So it includes shape and texture equally in its decision-making process \cite{Li2021}\cite{Co2021}\cite{Chung2023}. Which claims to achieve substantial improvements on ImageNet. \\
		The reason for the existence of texture bias is the shortcut learning from \ac{cnn}s \cite{Geirhos2020}, probably also influenced by unnatural data augmentation techniques \cite{Hermann2020}. Research found that shape information still plays an essential role in decision-making of many texture-biased \ac{dnn}s \cite{Tabak2023}.\\
		In contrast to past research, recent research states that a bias towards texture or shape can not explain the ability to generalize \cite{Gavrikov2024}. The relevance of bias is in question and is probably not as important as thought for generalization and maybe performance. %; otherwise, there would not be much research on shape texture bias.
		%\paragraph{Generalization:} ...
		\paragraph{Sim-to-real:} Using a synthetic dataset from a virtual environment became the standard procedure to quickly generate a massive amount of labeled data for instance segmentation \cite{Danielczuk2019}\cite{Xie2020}\cite{Xie2021}\cite{Shao2018}\cite{Toda2019}. To overcome the sim-to-real gap, the quality of texture plays a crucial role \cite{Tabak2023}\cite{Martinez2019}; That makes it appropriate to use a simulation software with a powerful and realistic-looking renderer for data generation, such as Unreal Engine 5 \cite{Romero2022}.\\
		Another successful technique to transfer well from sim to real is domain randomization \cite{Raj2023}. A variation to the synthetic data is applied to randomly modify shape, texture, colors, lightning (exposure), camera angles and cropping, blur, and noise. These random modifications bring the data closer to reality, where such modification also happens. Thus, the improvement is explainable. This variation can also be applied in a data-augmentation step after data generation \cite{Kar2022}.\\
		Many open questions remain about the sim-to-real transfer and many approaches lacking in generalization when \ac{dnn}s are only trained on synthetic data \cite{Doersch2019}. Modern and future render technology and highly realistic simulation software could improve sim-to-real transfer in instance segmentation even more.
		\clearpage
		\paragraph{Input Type:} Since the beginning of instance segmentation, depth data has played a vital role \cite{Silbermann2012}. It comes from the fact that this is a task based heavily on 3D information. Objects can be stacked on each other, and there may be only a small piece of an object to see;
		Thus, 3D information is crucial to precisely segment all objects from each other. Assisting an instance segmentation \ac{dnn}, providing information about the depth is therefore an obvious and understandable approach.\\
		How influential the depth information really is for segmentation accuracy and if RGB-only images do provide not enough 3D information by themselves is an open question; some recent researches show a trend to RGB-only approaches \cite{Raj2023}\cite{Zakeri2024}.\\
		There is also a depth-information-only approach due to the better sim-to-real ability of depth data, which could caused by the simpler nature of this data type \cite{Danielczuk2019}.\\\\
		Widespread is the use of depth as the fourth channel (RGB-D), yet the results are disagreed \cite{LÃ¼ling2021}\cite{Zakeri2024}.
		But the research gets even further to the question of the best way to implement depth information in \ac{dnn} \cite{Xiang2021}\cite{Xie2020}\cite{Pei2024}\cite{Yasir2022}\cite{Shao2018}\cite{Ye2017}.\\
		Also, the model itself used, for instance segmentation, changes the effectiveness of the used input types \cite{Xiang2021}.\\
		In conclusion, there is no absolute best input type, which always leads to the best segmentation masks. Factors like domain, brightness, \ac{dnn} architecture, and data quality could play a vital role in the choice of the input type, which makes optimizing instance segmentation even harder. The success of RGB-only input type in recent research \cite{Raj2023}\cite{Zakeri2024} can maybe be explained by the increasing quality of synthetic data but still needs more research to be confirmed.
		\paragraph{Shape Texture Amount:} Finally, no research was found that investigates the influence of shape or texture quantity on the accuracy of instance segmentation. Even if this question seems unimportant at first, a closer look is worth it. It appears unambiguous that more shapes and textures lead to better generalization and accuracy under the assumption of enough data amount. However, the quantity of how much it improves the accuracy could be very intriguing. 
		

	\clearpage
	\section{Related Work}
	\label{sec:related-work}
		%Investigating the amount of shape and texture with depth data towards generalization, bias, and sim-to-real seems to be novel and unique. Therefore, no comparable work was found. \\
		%This paper shows, among other things, practical results and shows if research in generalization, bias, and sim-to-real is reproducible in this specific practical use-case.\\
		Related work in this context is \citetitle{Gavrikov2024} \cite{Gavrikov2024}. The work from \citeauthor{Gavrikov2024} analyzes the relation between bias and generalization, as well as this work also (indirectly) investigates in the influence of bias towards generalization. This study will only focus on shape-texture bias, while \citetitle{Gavrikov2024} also analyzes spectral bias and critical bands bias. Moreover, this work examines the task of instance segmentation while the paper from \citeauthor{Gavrikov2024} is focused on classification tasks.\\
		Another related work is \citetitle{Raj2023} \cite{Raj2023}, which also addresses instance segmentation with Mask R-CNN for bin-picking with focus on the input-type as this study also do. The train data is also synthetic and so the sim-to-real challenge also appears. The work from \citeauthor{Raj2023} delimitates itself from this work, by focusing more on domain randomness in the data and also includes a grasp pose planner, which both are not covered in this study.\\
		The paper \citetitle{Tabak2023} from \citeauthor{Tabak2023} \cite{Tabak2023}, investigates also in the the shape-texture bias and found that segmentation models are biased towards texture but still include shape-information in their decision-making. Other than paper \cite{Tabak2023} this work uses the bin-picking domain while the previously mentioned paper takes part in a biological domain. interestingly the work from \citeauthor{Tabak2023} does not try to overcome the texture-bias and uses highly realistic synthetic data to achieve a precise segmentation result and to overcome the sim-to-real task, which is also an important part of this work. This work, in contrast, does not try to utilize the texture-bias specifically, else the bias the investigated. Both works have in common that they use highly realistic synthetic data. This work uses Unreal Engine 5 for data generation while the paper just mentioned uses Blender. The paper shows that models trained on only synthetic data can achieve a \ac{iou} between 45\% and 63\%.\\
		Next, the paper \citetitle{Geirhos2022} \cite{Geirhos2022} have foundings towards the improved accuracy when increasing shape-biased in \ac{cnn}-based models. This is an interesting founding which will be indirectly also checked by this work. The cited paper also claims that \ac{cnn} base models are biased towards texture when trained on ImageNet on the object classification task. This work will proof this on the 3xM dataset within the task of instance segmentation. This work uses the Mask R-CNN which is \ac{cnn}-based.
		\clearpage
		For the sim-to-real transfer with the here proposed dataset, a comparison with another study's results are not possible due to the fact, that it is a novel, here proposed, dataset. The also used OCID dataset \cite{Suchi2019} is used more widely and most similar is the paper \citetitle{Xiang2021} \cite{Xiang2021}. It also uses Mask R-CNN \cite{Kaiming2017} and varies with RGB and RGBD as input data. The methodology and metrics in this paper are used differently, thus a comparison is not possible. %, but it can give a rough impression and help through the evaluation.
		
		% with the "Learning RGB-D Feature Embeddings for Unseen Object Instance Segmentation" \cite{Xiang2021} paper is done because the work also uses Mask R-CNN \cite{Kaiming2017} and varies with RGB and RGBD as input data. Moreover, it calculates metrics on the OCID dataset \cite{Suchi2019}, an available dataset suitable for bin-picking. The quantity variation is missing.
	
	\section{Hypothesis Statement}
	\label{sec:hypothesis-statement}	
		Through 3 experiments, this study will try to prove or disprove the following two claims. One for the core focus depth and one claim for the core focus shape-texture quantity: 
		\begin{enumerate}
			\item "Combining RGB and depth data combines texture and shape bias, leading to better generalization and sim-to-real ability." % better instance segmentation results
			\item "More distinction in shapes leads to higher shape awareness, better generalization, and sim-to-real ability. Furthermore, more distinction in texture leads to higher texture awareness, better generalization, and sim-to-real ability."
			%\item "When using RGB-D as input, less unique shapes and textures are needed for the same instance segmentation accuracy as using only RGB as Input."
		\end{enumerate}
		The 1. claim was chosen through the findings of a bias towards texture in instance segmentation \cite{Theodoridis2022} and the fact that depth data only contains shape information. In that way, the \ac{dnn} could be encouraged to use more shape information for decision-making. In addition, more balanced decision-making between texture and shape information could lead to better results \cite{Li2021}\cite{Co2021}\cite{Chung2023}.\\
		For the 2. claim, there is no foundation for the claim, apart from the fact that \ac{dnn}s (and \ac{cnn}s specifically) need a huge amount of data to generalize well \cite{Cho2016}\cite{Luca2022}. That could mean that more different shapes and textures also increase the ability to generalize, bridge from sim to real, and probably increase the decision-making towards shape/texture.
		%There is also no foundation for the 3. claim, except due to the additional information about shape and the probably increased shape awareness, the \ac{dnn} may need fewer different shapes and textures to achieve a similar precision and generalization as the \ac{dnn} trained with only RGB images and more different shapes and textures in the train-data.
	
	



			